{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Scenario_C.xlsx file into a pandas DataFrame, the first tab is 'HH', second is 'HA', the third is 'AH', and teh fourth is 'AA'\n",
    "df_hh = pd.read_excel('Scenario_C.xlsx', sheet_name='HH')\n",
    "df_ha = pd.read_excel('Scenario_C.xlsx', sheet_name='HA')\n",
    "df_ah = pd.read_excel('Scenario_C.xlsx', sheet_name='AH')\n",
    "df_aa = pd.read_excel('Scenario_C.xlsx', sheet_name='AA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the four dataframes into one, adding a new column 'Configuration' to indicate the configuration\n",
    "df_hh['Configuration'] = 'HH'\n",
    "df_ha['Configuration'] = 'HA'\n",
    "df_ah['Configuration'] = 'AH'\n",
    "df_aa['Configuration'] = 'AA'\n",
    "df = pd.concat([df_hh, df_ha, df_ah, df_aa], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in df, rename the the pilots to be the following: 'Jacob': Pilot 1, 'Chan': Pilot 2, 'Grimmer': Pilot 3, 'Schnell': Pilot 4, 'McIntyre': Pilot 5, 'Smith': Pilot 6, 'Fleischmann': Pilot 7\n",
    "df['Lead_Pilot'] = df['Lead_Pilot'].replace({'Jacob': 'Pilot 1', 'Chan': 'Pilot 2', 'Grimmer': 'Pilot 3', 'Schnell': 'Pilot 4', 'McIntyre': 'Pilot 5', 'Fleischmann': 'Pilot 6', 'Smith': 'Pilot 7'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average 'CM{i}_MOP_Time_to_Intercept_s' for i = 1, ..., 5 and add to a new column 'Avg_Time_to_Intercept_s'\n",
    "df['Avg_Time_to_Intercept_s'] = df[[f'CM{i}_MOP_Time_to_Intercept_s' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Avg_Time_to_Consent_s'] = df[[f'CM{i}_MOP_Time_to_Consent_s' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Avg_Airspeed_Diff_at_Intercept_kt'] = df[[f'CM{i}_Airspeed_Diff_at_Intercept_kt' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Avg_Heading_Diff_at_Intercept_deg'] = df[[f'CM{i}_Heading_Diff_at_Intercept_deg' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Avg_Altitude_Offset_at_Intercept_ft'] = df[[f'CM{i}_Altitude_Offset_at_Intercept_ft' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Avg_Distance_from_CM_at_Intercept_nm'] = df[[f'CM{i}_Distance_from_CM_at_Intercept_nm' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Avg_Aspect_at_MELD_Range_deg'] = df[[f'CM{i}_Aspect_at_MELD_Range_deg' for i in range(1, 6)]].mean(axis=1)\n",
    "df['Proportion_Intercepted_by_Lead'] = df[[f'CM{i}_Interceptor Role' for i in range(1, 6)]].apply(lambda x: sum(x == 'Lead') / len(x), axis=1)\n",
    "df['Correct_Acquisition'] = df['Correct_Sort'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "df['Avg_Heading_Diff_at_Intercept_deg'] = df['Avg_Heading_Diff_at_Intercept_deg'].abs()\n",
    "df.loc[df['Avg_Airspeed_Diff_at_Intercept_kt'] < 0, 'Avg_Airspeed_Diff_at_Intercept_kt'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mop_list = ['Proportion_SAMs_Identified', 'Avg_SAM_ID_Time_s', 'Lead_Altitude_Deviation_Count', 'Wingman_Altitude_Deviation_Count',\n",
    "            'Lead_Altitude_Deviation_Integrated_ft_s', 'Wingman_Altitude_Deviation_Integrated_ft_s', 'Proportion_CMs_Intercepted',\n",
    "            'Avg_Time_to_Intercept_s', 'Avg_Time_to_Consent_s', 'Avg_Airspeed_Diff_at_Intercept_kt', 'Avg_Heading_Diff_at_Intercept_deg',\n",
    "            'Avg_Altitude_Offset_at_Intercept_ft', 'Avg_Distance_from_CM_at_Intercept_nm', 'Avg_Aspect_at_MELD_Range_deg',\n",
    "            'Num_Tactical_Comms', 'Correct_Acquisition', 'Scenario_Duration_s', 'Proportion_Intercepted_by_Lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_dic = {'Proportion_SAMs_Identified': 'Proportion of Surface Threats Identified', 'Avg_SAM_ID_Time_s': 'Average Surface Threat ID Time (s)',\n",
    "                  'Lead_Altitude_Deviation_Count': 'Lead Altitude Deviation Count', 'Wingman_Altitude_Deviation_Count': 'Wingman Altitude Deviation Count',\n",
    "                  'Lead_Altitude_Deviation_Integrated_ft_s': 'Lead Altitude Deviation Integrated (ft·s)', 'Wingman_Altitude_Deviation_Integrated_ft_s': 'Wingman Altitude Deviation Integrated (ft·s)',\n",
    "                    'Proportion_CMs_Intercepted': 'Proportion of CMs Intercepted', 'Avg_Time_to_Intercept_s': 'Average Time to Intercept (s)',\n",
    "                    'Avg_Time_to_Consent_s': 'Average Time to Consent (s)', 'Avg_Airspeed_Diff_at_Intercept_kt': 'Average Airspeed Difference at Intercept (kt)',\n",
    "                    'Avg_Heading_Diff_at_Intercept_deg': 'Average Heading Difference at Intercept (deg)', 'Avg_Altitude_Offset_at_Intercept_ft': 'Average Altitude Offset at Intercept (ft)',\n",
    "                    'Avg_Distance_from_CM_at_Intercept_nm': 'Average Distance from CM at Intercept (nm)', 'Avg_Aspect_at_MELD_Range_deg': 'Average Aspect at MELD Range (deg)',\n",
    "                    'Num_Tactical_Comms': 'Update Score', 'Correct_Acquisition': 'Correct Target Acquisition', 'Scenario_Duration_s': 'Scenario Duration (s)',\n",
    "                    'Proportion_Intercepted_by_Lead': 'Proportion of CMs Intercepted by Lead'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pilots = sorted(set(df['Lead_Pilot']))\n",
    "\n",
    "markers = ['o', 's', 'D', '^', 'v', '<', '>', 'P', 'X', '*']\n",
    "colors = cm.get_cmap('tab10', len(all_pilots)).colors\n",
    "\n",
    "pilot_styles = {\n",
    "    pilot: {'marker': markers[i % len(markers)],\n",
    "            'color': colors[i % len(colors)]}\n",
    "    for i, pilot in enumerate(all_pilots)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mops(df, mop, scenario, pilot_styles):\n",
    "    col = mop\n",
    "    if scenario == 'C':\n",
    "        configs = ['HH', 'HA', 'AH', 'AA']\n",
    "    elif scenario == 'D':\n",
    "        configs = ['HA', 'AA']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Boxplot\n",
    "    boxprops = dict(linestyle='-', linewidth=2, color='blue')\n",
    "    medianprops = dict(linestyle='-', linewidth=2.5, color='red')\n",
    "    data_for_box = [\n",
    "        df.loc[df['Configuration'] == c, col].dropna() \n",
    "        if df.loc[df['Configuration'] == c, col].dropna().size > 0 \n",
    "        else [np.nan]\n",
    "        for c in configs\n",
    "]\n",
    "    plt.boxplot(data_for_box, labels=configs, boxprops=boxprops, medianprops=medianprops)\n",
    "    # plt.boxplot(\n",
    "    #     [df[df['Configuration'] == c][col] for c in configs],\n",
    "    #     labels=configs, boxprops=boxprops, medianprops=medianprops\n",
    "    # )\n",
    "\n",
    "    # --- Assign markers and colors per pilot ---\n",
    "    # unique_pilots = sorted(df['Lead_Pilot'].unique())\n",
    "    # markers = ['o', 's', 'D', '^', 'v', '<', '>', 'P', 'X', '*']\n",
    "    # colors = cm.get_cmap('tab10', len(unique_pilots)).colors  # or use 'tab20'\n",
    "\n",
    "    # pilot_styles = {\n",
    "    #     pilot: {'marker': markers[i % len(markers)],\n",
    "    #             'color': colors[i % len(colors)]}\n",
    "    #     for i, pilot in enumerate(unique_pilots)\n",
    "    # }\n",
    "\n",
    "    # --- Scatter raw points with jitter ---\n",
    "    for i, config in enumerate(configs, start=1):\n",
    "        subset = df[df['Configuration'] == config]\n",
    "        for pilot, pilot_df in subset.groupby('Lead_Pilot'):\n",
    "            style = pilot_styles[pilot]\n",
    "            jitter = np.random.uniform(-0.1, 0.1, size=len(pilot_df))\n",
    "            plt.scatter(\n",
    "                np.full(len(pilot_df), i) + jitter,\n",
    "                pilot_df[col],\n",
    "                alpha=0.7,\n",
    "                s=60,\n",
    "                label=pilot if i == 1 else None,  # only add to legend once\n",
    "                marker=style['marker'],\n",
    "                color=style['color'],\n",
    "                edgecolor='black'\n",
    "            )\n",
    "\n",
    "    # col_label = col.replace('_', ' ')\n",
    "    col_label = plot_title_dic[col]\n",
    "    # plt.title(f'{col_label} by Configuration')\n",
    "    plt.title(f'Scenario {scenario}\\n{col_label} by Configuration')\n",
    "    plt.ylabel(f'{col_label}')\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "    # if 'proportion' is in the column name, set y limit to 0 to 1\n",
    "    if 'Proportion' in col:\n",
    "        plt.ylim(0, 1.05)\n",
    "\n",
    "    # Unique legend for pilots\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), title='Pilot',\n",
    "               bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Scenario {scenario}/Plots/{col_label}.jpg', dpi=700)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_summary(df, scenario):\n",
    "    summary = df.groupby('Configuration')[mop_list].agg(['mean', 'std']).reset_index()\n",
    "    # Flatten MultiIndex columns\n",
    "    summary.columns = ['_'.join(col).strip() if col[1] else col[0] for col in summary.columns.values]\n",
    "    summary.to_csv(f'Scenario {scenario}/Data_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_summary(df, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mop in mop_list:\n",
    "    plot_mops(df, mop, 'C', pilot_styles=pilot_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, do the same with scenario D\n",
    "# read the Scenario_D.xlsx file into a pandas DataFrame, the first tab is 'HH', second is 'HA', the third is 'AH', and teh fourth is 'AA'\n",
    "# df_d_hh = pd.read_excel('Scenario_D.xlsx', sheet_name='HH')\n",
    "df_d_ha = pd.read_excel('Scenario_D.xlsx', sheet_name='HA')\n",
    "# df_d_ah = pd.read_excel('Scenario_D.xlsx', sheet_name='AH')\n",
    "df_d_aa = pd.read_excel('Scenario_D.xlsx', sheet_name='AA')\n",
    "\n",
    "# combine the four dataframes into one, adding a new column 'Configuration' to indicate the configuration\n",
    "# df_d_hh['Configuration'] = 'HH'\n",
    "df_d_ha['Configuration'] = 'HA'\n",
    "# df_d_ah['Configuration'] = 'AH'\n",
    "df_d_aa['Configuration'] = 'AA'\n",
    "df_d = pd.concat([df_d_ha, df_d_aa], ignore_index=True)\n",
    "\n",
    "# in df, rename the the pilots to be the following: 'Jacob': Pilot 1, 'Chan': Pilot 2, 'Grimmer': Pilot 3, 'Schnell': Pilot 4, 'McIntyre': Pilot 5, 'Smith': Pilot 6, 'Fleischmann': Pilot 7\n",
    "df_d['Lead_Pilot'] = df_d['Lead_Pilot'].replace({'Jacob': 'Pilot 1', 'Chan': 'Pilot 2', 'Grimmer': 'Pilot 3', 'Schnell': 'Pilot 4', 'McIntyre': 'Pilot 5', 'Fleischmann': 'Pilot 6', 'Smith': 'Pilot 7',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d['Avg_Time_to_Intercept_s'] = df_d[[f'CM{i}_MOP_Time_to_Intercept_s' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Avg_Time_to_Consent_s'] = df_d[[f'CM{i}_MOP_Time_to_Consent_s' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Avg_Airspeed_Diff_at_Intercept_kt'] = df_d[[f'CM{i}_Airspeed_Diff_at_Intercept_kt' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Avg_Heading_Diff_at_Intercept_deg'] = df_d[[f'CM{i}_Heading_Diff_at_Intercept_deg' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Avg_Altitude_Offset_at_Intercept_ft'] = df_d[[f'CM{i}_Altitude_Offset_at_Intercept_ft' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Avg_Distance_from_CM_at_Intercept_nm'] = df_d[[f'CM{i}_Distance_from_CM_at_Intercept_nm' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Avg_Aspect_at_MELD_Range_deg'] = df_d[[f'CM{i}_Aspect_at_MELD_Range_deg' for i in range(1, 6)]].mean(axis=1)\n",
    "df_d['Proportion_Intercepted_by_Lead'] = df_d[[f'CM{i}_Interceptor Role' for i in range(1, 6)]].apply(lambda x: sum(x == 'Lead') / len(x), axis=1)\n",
    "df_d['Correct_Acquisition'] = df_d['Correct_Sort'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "df_d['Avg_Heading_Diff_at_Intercept_deg'] = df_d['Avg_Heading_Diff_at_Intercept_deg'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_summary(df_d, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mop in mop_list:\n",
    "    plot_mops(df_d, mop, 'D', pilot_styles=pilot_styles)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedford = pd.read_excel('Bedford Results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedford['Lead_Pilot'] = bedford['Lead'].replace({'Chuck': 'Pilot 1', 'Indy': 'Pilot 2', 'Tars': 'Pilot 3', 'MACH': 'Pilot 4', 'Savage': 'Pilot 5', 'Pig': 'Pilot 6', 'Assassin': 'Pilot 7'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedford = bedford.drop_duplicates(subset=['Configuration', 'Scenario', 'Lead_Pilot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bedford(df, scenario, pilot_styles):\n",
    "    col = 'Bedford'\n",
    "    configs = ['HH', 'HA', 'AH', 'AA']\n",
    "    df_scenario = df[df['Scenario'] == scenario].copy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # --- Boxplot data, dropping NaNs and skipping empty sets ---\n",
    "    data_for_box = []\n",
    "    valid_configs = []\n",
    "    for c in configs:\n",
    "        subset = df_scenario.loc[df_scenario['Configuration'] == c, col].dropna()\n",
    "        if len(subset) > 0:\n",
    "            data_for_box.append(subset)\n",
    "            valid_configs.append(c)\n",
    "\n",
    "    boxprops = dict(linestyle='-', linewidth=2, color='blue')\n",
    "    medianprops = dict(linestyle='-', linewidth=2.5, color='red')\n",
    "    plt.boxplot(data_for_box, labels=valid_configs,\n",
    "                boxprops=boxprops, medianprops=medianprops)\n",
    "\n",
    "    # --- Overlay raw data with consistent pilot styling ---\n",
    "    for i, config in enumerate(valid_configs, start=1):\n",
    "        subset = df_scenario[df_scenario['Configuration'] == config].dropna(subset=[col])\n",
    "        for pilot, pilot_df in subset.groupby('Lead_Pilot'):\n",
    "            if pilot not in pilot_styles:\n",
    "                continue\n",
    "            style = pilot_styles[pilot]\n",
    "            jitter = np.random.uniform(-0.1, 0.1, size=len(pilot_df))\n",
    "            plt.scatter(\n",
    "                np.full(len(pilot_df), i) + jitter,\n",
    "                pilot_df[col],\n",
    "                alpha=0.7,\n",
    "                s=60,\n",
    "                marker=style['marker'],\n",
    "                color=style['color'],\n",
    "                edgecolor='black',\n",
    "               label=pilot if i == 1 else None  # only once for legend\n",
    "            )\n",
    "\n",
    "    # --- Titles, labels, legend ---\n",
    "    plt.title(f'{col} Workload Rating by Configuration\\nScenario {scenario}',\n",
    "              fontsize=14, pad=10)\n",
    "    plt.ylabel('Bedford Score')\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(),\n",
    "               title='Pilot', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Save plot ---\n",
    "    plt.savefig(f'Workload/{col}_Scenario_{scenario}.jpg', dpi=700)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bedford(bedford, 'C', pilot_styles)\n",
    "plot_bedford(bedford, 'D', pilot_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hh_overall_c = pd.read_excel('SCORES_Scenario_C_Summary.xlsx', sheet_name='HH')\n",
    "df_hh_overall_c['Configuration'] = 'HH'\n",
    "df_ha_overall_c = pd.read_excel('SCORES_Scenario_C_Summary.xlsx', sheet_name='HA')\n",
    "df_ha_overall_c['Configuration'] = 'HA'\n",
    "df_ah_overall_c = pd.read_excel('SCORES_Scenario_C_Summary.xlsx', sheet_name='AH')\n",
    "df_ah_overall_c['Configuration'] = 'AH'\n",
    "df_aa_overall_c = pd.read_excel('SCORES_Scenario_C_Summary.xlsx', sheet_name='AA')\n",
    "df_aa_overall_c['Configuration'] = 'AA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall_c = pd.concat([df_hh_overall_c, df_ha_overall_c, df_ah_overall_c, df_aa_overall_c], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the row where 'Configuration' == 'HA', 'Lead_Pilot' == 'Grimmer'\n",
    "df_overall_c = df_overall_c[~((df_overall_c['Configuration'] == 'HA') & (df_overall_c['Lead_Pilot'] == 'Grimmer'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall_c['Lead_Pilot'] = df_overall_c['Lead_Pilot'].replace({'Jacob': 'Pilot 1', 'Chan': 'Pilot 2', 'Grimmer': 'Pilot 3', 'Schnell': 'Pilot 4', 'McIntyre': 'Pilot 5', 'Fleischmann': 'Pilot 6', 'Smith': 'Pilot 7'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_metric(df, col, scenario, pilot_styles):\n",
    "\n",
    "    configs = ['HH', 'HA', 'AH', 'AA']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # --- Boxplot data ---\n",
    "    data_for_box = []\n",
    "    valid_configs = []\n",
    "    for c in configs:\n",
    "        subset = df.loc[df['Configuration'] == c, col].dropna()\n",
    "        if len(subset) > 0:\n",
    "            data_for_box.append(subset)\n",
    "            valid_configs.append(c)\n",
    "\n",
    "    if not valid_configs:\n",
    "        print(f\"⚠️ No valid data found for {col} (Scenario {scenario}). Skipping plot.\")\n",
    "        return\n",
    "\n",
    "    boxprops = dict(linestyle='-', linewidth=2, color='blue')\n",
    "    medianprops = dict(linestyle='-', linewidth=2.5, color='red')\n",
    "    plt.boxplot(data_for_box, labels=valid_configs,\n",
    "                boxprops=boxprops, medianprops=medianprops)\n",
    "\n",
    "    # --- Overlay raw data with consistent pilot colors/markers ---\n",
    "    for i, config in enumerate(valid_configs, start=1):\n",
    "        subset = df[df['Configuration'] == config].dropna(subset=[col])\n",
    "        for pilot, pilot_df in subset.groupby('Lead_Pilot'):\n",
    "            if pilot not in pilot_styles:\n",
    "                continue\n",
    "            style = pilot_styles[pilot]\n",
    "            jitter = np.random.uniform(-0.1, 0.1, size=len(pilot_df))\n",
    "            plt.scatter(\n",
    "                np.full(len(pilot_df), i) + jitter,\n",
    "                pilot_df[col],\n",
    "                alpha=0.7,\n",
    "                s=60,\n",
    "                marker=style['marker'],\n",
    "                color=style['color'],\n",
    "                edgecolor='black',\n",
    "                label=pilot if i == 1 else None\n",
    "            )\n",
    "\n",
    "    # --- Titles, labels, legend ---\n",
    "    col_label = col.replace('_', ' ')\n",
    "    plt.title(f'{col_label} by Configuration\\nScenario {scenario}',\n",
    "              fontsize=14, pad=10)\n",
    "    plt.ylabel(col_label)\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(),\n",
    "               title='Pilot', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Save plot ---\n",
    "    plt.savefig(f'Scenario C/{col}_Scenario_{scenario}.jpg', dpi=700)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_metric(df_overall_c, 'Overall Score', 'C', pilot_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
